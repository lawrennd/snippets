\ifndef{linearRegressionIterative}
\define{linearRegressionIterative}

\include{_ml/includes/regression.md}
\include{_ml/includes/regression-contour-plot.md}
\include{_ml/includes/regression-gradient-descent.md}
\include{_ml/includes/regression-stochastic-gradient-descent.md}

\editme

\subsection{Reflection on Linear Regression and Supervised Learning}

Think about:

1. What effect does the learning rate have in the optimization? What's the effect of making it too small, what's the effect of making it too big? Do you get the same result for both stochastic and steepest gradient descent?

2. The stochastic gradient descent doesn't help very much for such a small data set. It's real advantage comes when there are many.

\endif
